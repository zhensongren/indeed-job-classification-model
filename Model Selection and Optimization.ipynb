{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary packages and read the pre-processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('job_with_title.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['description']\n",
    "y = df['title_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "X = tfidf.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X, y, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=6, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.figure(figsize=(5,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_id_df = df[['search_title', 'title_id']].drop_duplicates().sort_values('title_id')\n",
    "title_to_id = dict(title_id_df.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, df.index, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, model.predict(X_test))\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=title_id_df['search_title'].values, yticklabels=title_id_df['search_title'].values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most related words for each job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "\n",
    "N = 2\n",
    "for search_title, title_id in sorted(title_to_id.items()):\n",
    "    indices = np.argsort(model.coef_[title_id])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "    bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "\n",
    "    print(\"# {}:\".format(search_title))\n",
    "    print(\"   ## Most correlated unigrams: {}\".format(',   '.join(unigrams)))\n",
    "    print(\"   ## Most correlated bigrams: {}\".format(',   '.join(bigrams)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(model, 'indeed_LinearSVC.pkl')\n",
    "joblib.dump(tfidf, 'tfidfVectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post = [\"\"\"\n",
    "Data Scientist\n",
    "SAVE\n",
    "\n",
    "Home Depot\n",
    "Houston, TX\n",
    "Apply on Glassdoor\n",
    "Apply on LinkedInApply on The Home Depot CareersApply on ZipRecruiterApply on The Home Depot Jobs | Jobs At Home DepotApply on Science Jobs\n",
    "18 days agoFull-time\n",
    "Position Description:\n",
    "\n",
    "POSITION PURPOSE\n",
    "\n",
    "A Data Scientist leverages their technical abilities to synthesize complex analytical tasks into easily understood data-driven stories. Data Scientists are responsible for organizing, analyzing, and then sharing insights gleaned from data. This positions develops predictive systems and algorithms for identifying trends and driving business solutions. This position also utilizes industry-leading standards for working with very large datasets to extract meaningful business information using statistics, machine learning, and heuristics. This position operates with minimal supervision, and once given general assignments, prioritizes and executes tasks.\n",
    "\n",
    "MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES\n",
    "\n",
    "20% - Designs and develops algorithms and models that use large datasets to derive business insights 20% - Establishes scalable, efficient processes for large scale data analyses, model development, and model implementation 20% - Ensures the quality of work output by displaying a keen attention to detail 20% - Presents findings in easily understood ways, focuses on how the data analytics fits into the bigger picture 10% - Mentors and develops the technical skills of Analysts and Sr. Analysts 10% - Seeks further knowledge on key developments within data science, technical skill sets, and additional data sources within Home Depot\n",
    "\n",
    "NATURE AND SCOPE\n",
    "\n",
    "This position reports to Manager or Sr Manager.\n",
    "\n",
    "This position has 0 direct reports.\n",
    "\n",
    "ENVIRONMENTAL JOB REQUIREMENTS\n",
    "\n",
    "Environment:\n",
    "\n",
    "Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.\n",
    "\n",
    "Travel:\n",
    "\n",
    "Typically requires overnight travel less than 10% of the time.\n",
    "\n",
    "Additional Environmental Job Requirements:\n",
    "\n",
    "ESSENTIAL SKILLS:\n",
    "\n",
    "MINIMUM QUALIFICATIONS\n",
    "\n",
    "Must be eighteen years of age or older.\n",
    "\n",
    "Must be legally permitted to work in the United States.\n",
    "\n",
    "Additional Minimum Qualifications:\n",
    "\n",
    "Education Required:\n",
    "\n",
    "The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.\n",
    "\n",
    "Years of Relevant Work Experience: 4 years\n",
    "\n",
    "Physical Requirements:\n",
    "\n",
    "Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.\n",
    "\n",
    "Additional Qualifications:\n",
    "\n",
    "Preferred Qualifications:\n",
    "\n",
    "Masters Degree in Computer Science, Math, Engineering, or related quantitative field and 3+ years experience in position offered or related position\n",
    "\n",
    "Knowledge, Skills, Abilities and Competencies:- Extensive experience in a hands on analytical role, with focus on Root Cause Analysis and Strong relational database skills (Access, SQL Server, Postgres, etc.) and SQL skills (writing complex queries to pull large sets of data, performing analysis using SQL queries) Ability to process large amounts of data through high throughput computing tools (HTCondor, Hadoop, etc.) Strong knowledge in statistical analysis and model building using software (R, SAS, etc.) Experience in data visualization and building dashboards (Tableau, R, Excel, etc.) Strong understanding of Object Oriented Programming Language (C++, Java, Python, etc.) Proficiency in Excel (Pivot Tables, V-Lookup, Macros, VBA, etc.) a must\n",
    "\n",
    "We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load('indeed_LinearSVC.pkl')\n",
    "tfidf = joblib.load('tfidfVectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(tfidf.transform(job_post))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
